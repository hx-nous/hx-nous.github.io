# 本篇综述主要讲解了GNN和LLM在图挖掘领域的结合相关情况

## 首先，本文讲解了图挖掘的重要性，GNN擅长结构建模，LLM擅长语义理解，然后列出了GNN和LLM在各自领域的应用。作者提出了GNN和LLM的三种结合方式：

1. GDL：GNN作为主要部分对LLM处理的节点信息进行处理，LLM模型就负责处理节点或边的语义信息转化为embedding提供给GNN。这个最容易落地，如推荐系统，文本属性图。
2. LDG：GNN辅助将图数据转化为LLM能理解的文本描述，然后LLM主导推理。如知识图谱问答，图推理任务。
3. GLCD：GNN和LLM共同作用，不再由其中一方主导，可以互相融合，共享embedding空间。例如GraphFormers，在每一层transformer里面嵌入GNN，在LLM处理语义信息的同时在层内补充结构信息。如跨模态任务。

## 总结，目前两者结合还没有统一的框架，只是一些各自的结合，而且不同模式各有优缺点：GdL 最易落地，LdG 更适合语言类任务，GLcd 效果最好但代价最大。作者还提到目前LLM的参数很多，算力消耗大、可解释性不足。